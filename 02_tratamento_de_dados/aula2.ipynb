{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dad6649",
   "metadata": {},
   "source": [
    "Coleta e organização de dados\n",
    "=========================\n",
    "\n",
    "Professor: Marcos Cesar Gritti  \n",
    "Email: cesargritti@gmail.com\n",
    "\n",
    "Neste notebook, vamos aprender a:\n",
    "\n",
    "1. Carregar fontes de dados;\n",
    "2. Transformação e teste de estacionaridade;\n",
    "3. ACF e PACF;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7bd79",
   "metadata": {},
   "source": [
    "1 - Carregar fontes de dados\n",
    "========================\n",
    "\n",
    "No dia a dia de trabalho, um Cientista de Dados se depara com diferentes tipos fontes de dados. Nem sempre, em sua equipe, haverá um Engenheiro de Dados disponível para te ajudar a coletar dados de interesse em um formato fácil de integração com seu ambiente de desenvolvimento Python (ou qualquer outro ambiente de desenvolvimento científico), no nosso caso, o Jupyter Notebook. Portanto, é fundamental que você domine os principais formatos e/ou fontes existentes no mercado, para que não dependa de um terceiro para uma rápida prototipação/experimentação.\n",
    "\n",
    "As principais fontes de dados, encontradas por um profissional da área, são:\n",
    "\n",
    "    Arquivos .csv;\n",
    "    Arquivos .json;\n",
    "    Arquivos .parquet;\n",
    "    Base de dados relacional SQL;\n",
    "    Base de dados não relacional NoSQL;\n",
    "\n",
    "Em empresas que seguem a filosofia **Data Driven** existirá, usualmente, uma pedaço de Software nominado de *Camada de Ingestão de Dados*. Esta camada, desenvolvida por Engenheiros de Dados, tem por objetivo centralizar diversas fontes de informação bruta (arquivos csv, json, parquet, imagens, audios, etc ...) em um único repositório (ou Buckets). Este repositório centralizado recebe o nome de **Data Lake**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c68f5d",
   "metadata": {},
   "source": [
    "1.1 - Arquivo csv - Exercício\n",
    "=======================\n",
    "\n",
    "A existência de arquivos csv em Data Lakes não é predominante, pois, apesar de ser um arquivo fácil de se manipular, não é o mais eficiente (redução de espaço em disco e otimização de tempo de leitura). Entretanto, é o tipo de arquivo mais encontrado quando a informação ainda não está disponível no **Data Lake** (exportação de planilhas Excel, base de dados do IBGE, entre outras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50da08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue, nesta célula, o arquivo csv \"inbound.csv\" usando o `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38355230",
   "metadata": {},
   "source": [
    "1.2 - Arquivo json - Exercício\n",
    "=======================\n",
    "\n",
    "É o formato mais utilizado por Engenheiros de Software, devido à sua compatibilidade com as tecnologias de desenvolvimento de APIs da atualidade. Consequentemente, a quantidade de arquivos json em Data Lakes é volumosa.\n",
    "\n",
    "No Pandas, importa-se um arquivo json utilizando o método read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a402700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue, nesta célula, o arquivo json \"inbound.json\" usando o `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbc350",
   "metadata": {},
   "source": [
    "1.3 - Arquivo parquet - Exercício\n",
    "==========================\n",
    "\n",
    "É um formato de armazenamento colunar, disponível em todos os projetos do ecossistema *Hadoop*. Em suma, um arquivo parquet permite armazenar e consultar o arquivo de forma eficiênte, o que justifica seu emprego na construção de **Data Lakes**.\n",
    "\n",
    "https://parquet.apache.org/\n",
    "\n",
    "A API do Pandas é intuitiva! Para carregar um arquivo parquet, utilizamos o método pd.read_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cf1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue, nesta célula, o arquivo parquet \"inbound.parquet\" usando o `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fbd8f",
   "metadata": {},
   "source": [
    "1.4 - União de datasets - Exercício\n",
    "============================\n",
    "\n",
    "Os dados da aula de hoje foram divididos em três arquivos (os quais carregamos na células anteriores). Pesquise na documentação do Pandas como unir as linhas dos três dataframes que carregamos anteriormente em um novo dataframe.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/index.html#api\n",
    "\n",
    "Dica: Concatenar é a palavra chave de pesquisaq\n",
    "\n",
    "Por fim, indexe o conjunto de dados pela coluna ``date``, convertendo-a para um objeto do tipo `datetime`, ordenando-os de forma ascendente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec73cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para o exercício 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a8d59",
   "metadata": {},
   "source": [
    "2 - Teste de estacionaridade - Exercício\n",
    "========================================\n",
    "\n",
    "Verifique se a Seŕie Temporal é estacionária utilizando um dos seguintes testes:\n",
    "- (ADF) Augmented Dickey Fuller;\n",
    "- (KPSS) Kwiatkowski-Phillips-Schmidt-Shin\n",
    "\n",
    "Caso seŕie temporal original não seja estacionária, aplique diferenciações e/ou transformações\n",
    "para tornar a série estacionária.\n",
    "\n",
    "Dica: Utilize a biblioteca `statsmodels` para testar as hipóteses de estacionaridade.  \n",
    "https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba8b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula paa o exercício 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea2bda",
   "metadata": {},
   "source": [
    "3 -  ACF e PACF - Exercício\n",
    "========================================\n",
    "\n",
    "Aplique a Função de Autocorrelação (ACF) e a Função de Autocorrelação Parcial (PACF) na série temporal.\n",
    "Interprete e discuta os resultados com o professor.\n",
    "\n",
    "Dica: Utilize a biblioteca `statsmodels` para testar as hipóteses de estacionaridade.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a655aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para o exercício 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
